{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_19_5_all",
      "provenance": [],
      "authorship_tag": "ABX9TyMTHD267WuISGc2jOkZS6jy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/internship/blob/master/VGG_19_5_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_acx8CPXZFZG",
        "colab_type": "code",
        "outputId": "839ab037-6df5-4270-823d-483e042578b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7xEnlkqG9a",
        "colab_type": "code",
        "outputId": "1def2639-1429-4116-d1fe-1061e88c059f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3l1xcHrqIBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMPeh8DBqJPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (299,299), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=224\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  img1=np.asarray(img)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],dimension,dimension,1)),3,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],dimension,dimension,1)),3,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ZbOR8ZqTfN",
        "colab_type": "code",
        "outputId": "c7d184d3-0b91-4806-db1e-8e2133a41671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mod=VGG19(include_top=True, weights='imagenet')\n",
        "mod.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 16s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL-5ABDhqUth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(last=True):   \n",
        "  K.clear_session() \n",
        "  mod=VGG19(include_top=True, weights='imagenet')\n",
        "  out_1=mod.layers[-2].output\n",
        "  out=Dense(3,activation='softmax')(out_1)\n",
        "  model=Model(inputs=mod.input,outputs=out)\n",
        "\n",
        "  if last:\n",
        "    for i in range(len(model.layers)):\n",
        "        model.layers[i].trainable = False\n",
        "  model.layers[-1].trainable=True\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvS8c2_XqWUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float32'), labels.astype('uint8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRqXPwk6qYHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Xwz33-qZob",
        "colab_type": "code",
        "outputId": "cc7b0966-1ab6-4f6b-d104-84dc34d4acc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=5\n",
        "  epoch=50\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "  plt.imshow(trn[0][0])\n",
        "  plt.show()\n",
        "  plt.imshow(tst[0][0])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model(last=False)\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(3e-4), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=4, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  del([trn_x,trn_y,trn,tst])\n",
        "  gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  for i in range(epoch):\n",
        "      hist=model.fit_generator(train_data,epochs=1,validation_data=[tst_x,to_categorical(tst_y)],steps_per_epoch=ln//4)\n",
        "      pre=model.predict(tst_x)\n",
        "      pre=np.argmax(pre,1)\n",
        "      new_acc=accuracy_score(pre,tst_y)\n",
        "      if new_acc>best:\n",
        "            best_accuracy_last[fold]=new_acc\n",
        "            best=new_acc\n",
        "            predictions_last_best[fold]=pre\n",
        "      history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "605/605 [==============================] - 222s 368ms/step - loss: 0.2504 - accuracy: 0.9026 - val_loss: 1.0295 - val_accuracy: 0.8258\n",
            "605/605 [==============================] - 222s 368ms/step - loss: 0.2504 - accuracy: 0.9026 - val_loss: 1.0295 - val_accuracy: 0.8258\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 224s 370ms/step - loss: 0.1747 - accuracy: 0.9322 - val_loss: 0.7840 - val_accuracy: 0.8383\n",
            "605/605 [==============================] - 224s 370ms/step - loss: 0.1747 - accuracy: 0.9322 - val_loss: 0.7840 - val_accuracy: 0.8383\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1864 - accuracy: 0.9273 - val_loss: 0.4309 - val_accuracy: 0.8538\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1864 - accuracy: 0.9273 - val_loss: 0.4309 - val_accuracy: 0.8538\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.4288 - val_accuracy: 0.8802\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.4288 - val_accuracy: 0.8802\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1241 - accuracy: 0.9542 - val_loss: 0.7641 - val_accuracy: 0.8600\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1241 - accuracy: 0.9542 - val_loss: 0.7641 - val_accuracy: 0.8600\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1012 - accuracy: 0.9631 - val_loss: 0.5388 - val_accuracy: 0.8802\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.1012 - accuracy: 0.9631 - val_loss: 0.5388 - val_accuracy: 0.8802\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.0778 - accuracy: 0.9717 - val_loss: 0.5529 - val_accuracy: 0.8942\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.0778 - accuracy: 0.9717 - val_loss: 0.5529 - val_accuracy: 0.8942\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.0727 - accuracy: 0.9738 - val_loss: 0.6147 - val_accuracy: 0.8927\n",
            "605/605 [==============================] - 225s 372ms/step - loss: 0.0727 - accuracy: 0.9738 - val_loss: 0.6147 - val_accuracy: 0.8927\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 224s 370ms/step - loss: 0.0942 - accuracy: 0.9659 - val_loss: 0.5836 - val_accuracy: 0.8927\n",
            "605/605 [==============================] - 224s 370ms/step - loss: 0.0942 - accuracy: 0.9659 - val_loss: 0.5836 - val_accuracy: 0.8927\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0510 - accuracy: 0.9823 - val_loss: 1.6991 - val_accuracy: 0.8289\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0510 - accuracy: 0.9823 - val_loss: 1.6991 - val_accuracy: 0.8289\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1153 - accuracy: 0.9637 - val_loss: 0.6323 - val_accuracy: 0.8663\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1153 - accuracy: 0.9637 - val_loss: 0.6323 - val_accuracy: 0.8663\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.7308 - val_accuracy: 0.8958\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.7308 - val_accuracy: 0.8958\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 1.6992 - val_accuracy: 0.8740\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 1.6992 - val_accuracy: 0.8740\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 1.2303 - val_accuracy: 0.8834\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 1.2303 - val_accuracy: 0.8834\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 1.4302 - val_accuracy: 0.8709\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 1.4302 - val_accuracy: 0.8709\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1459 - accuracy: 0.9483 - val_loss: 1.0013 - val_accuracy: 0.9207\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1459 - accuracy: 0.9483 - val_loss: 1.0013 - val_accuracy: 0.9207\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 1.0115 - val_accuracy: 0.9005\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 1.0115 - val_accuracy: 0.9005\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.9191 - val_accuracy: 0.8974\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.9191 - val_accuracy: 0.8974\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1154 - accuracy: 0.9656 - val_loss: 1.1142 - val_accuracy: 0.9114\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1154 - accuracy: 0.9656 - val_loss: 1.1142 - val_accuracy: 0.9114\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 1.0480 - val_accuracy: 0.8849\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 1.0480 - val_accuracy: 0.8849\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.6973 - val_accuracy: 0.9114\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.6973 - val_accuracy: 0.9114\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.9420 - val_accuracy: 0.9036\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.9420 - val_accuracy: 0.9036\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1123 - accuracy: 0.9634 - val_loss: 0.5568 - val_accuracy: 0.8896\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.1123 - accuracy: 0.9634 - val_loss: 0.5568 - val_accuracy: 0.8896\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.8308 - val_accuracy: 0.8554\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.8308 - val_accuracy: 0.8554\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.1245 - val_accuracy: 0.9067\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.1245 - val_accuracy: 0.9067\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 3.8346e-04 - accuracy: 0.9999 - val_loss: 1.6030 - val_accuracy: 0.9051\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 3.8346e-04 - accuracy: 0.9999 - val_loss: 1.6030 - val_accuracy: 0.9051\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.6628 - val_accuracy: 0.8896\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.6628 - val_accuracy: 0.8896\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 1.3185 - val_accuracy: 0.9051\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 1.3185 - val_accuracy: 0.9051\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.7950 - val_accuracy: 0.9082\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.7950 - val_accuracy: 0.9082\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.7157 - val_accuracy: 0.9067\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.7157 - val_accuracy: 0.9067\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.1447 - val_accuracy: 0.8896\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.1447 - val_accuracy: 0.8896\n",
            "Epoch 1/1\n",
            "Epoch 1/1\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.9304 - val_accuracy: 0.9067\n",
            "605/605 [==============================] - 223s 369ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.9304 - val_accuracy: 0.9067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et0Rppecqbr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index=str(index)\n",
        "type='all'\n",
        "model='VGG19'\n",
        "path = F\"/content/gdrive/My Drive/\"+model \n",
        "np.save(path+\"/best_accuracy_all_fold_\"+index+\"_\"+model+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold'+index+\"_\"+model+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "np.save(path+'/history_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",history_last)\n",
        "np.save(path+'/answers_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",answers_last)\n",
        "np.save(path+'/predictions_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last_best)\n",
        "np.save(path+'/times_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",times_last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJXDuyzqc_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}