{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_data",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOU+bDRZPIgGmLXCS9IpKQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/internship/blob/master/generate_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Ifk-2li6bc",
        "colab_type": "code",
        "outputId": "3dda6dd4-4f05-46c9-b667-48afbdf3b761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xyOCgyz4wjN",
        "colab_type": "code",
        "outputId": "4b42ad3a-dc27-48a5-924f-ca2d38425f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "pip install git+https://github.com/rcmalli/keras-squeezenet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-squeezenet.git\n",
            "  Cloning https://github.com/rcmalli/keras-squeezenet.git to /tmp/pip-req-build-rghhrh21\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-squeezenet.git /tmp/pip-req-build-rghhrh21\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-squeezenet==0.4 from git+https://github.com/rcmalli/keras-squeezenet.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (2.10.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (2.2.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-squeezenet==0.4) (3.13)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (0.9.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (2.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->keras-squeezenet==0.4) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-squeezenet==0.4) (1.0.8)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.6.0.post3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (47.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (1.6.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->keras-squeezenet==0.4) (0.4.8)\n",
            "Building wheels for collected packages: keras-squeezenet\n",
            "  Building wheel for keras-squeezenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-squeezenet: filename=keras_squeezenet-0.4-cp36-none-any.whl size=4425 sha256=465ea1cb479113d37278ae3a380f0c673f5e4d140affda6defb9fa39d536b145\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6qcjq986/wheels/15/75/ed/45fffbc76d921a5be07af533b774b35bbf40551334c51af91f\n",
            "Successfully built keras-squeezenet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-wcAaXD4yPG",
        "colab_type": "code",
        "outputId": "7624c376-cd64-4239-95c3-8775cb5dc5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras_squeezenet import SqueezeNet\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY59U01ejFIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import zipfile\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import zipfile\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import pandas as pd\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import zipfile\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (227,227), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=227\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['labels'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['images'])\n",
        "  img1=[]\n",
        "  for i in img:\n",
        "    img1.append(change(i))\n",
        "  img1=np.asarray(img1)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  return (trn_img,trn_y),(tst_img,tst_y)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WlukfqCaPPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzx7AGwAXnHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "15eb0224-cd2e-4aeb-83f2-8a3ddcd5b36f"
      },
      "source": [
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "from tqdm import tqdm\n",
        "for fld in tqdm(np.unique(df['fold'])):\n",
        "  img=np.asarray(df['image'])[df['fold']==fld]\n",
        "  labels=np.asarray(df['label'])[df['fold']==fld]\n",
        "  fold=np.asarray(df['fold'])[df['fold']==fld]\n",
        "  imgH=Hflip(img)\n",
        "  imgV=Vflip(img)\n",
        "  imgR=rotate(img)\n",
        "  images=[]\n",
        "  images.extend(imgH)\n",
        "  images.extend(imgV)\n",
        "  images.extend(imgR)\n",
        "  del([imgV,imgR,imgH])\n",
        "  gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "  dk={}\n",
        "  images1=[]\n",
        "  for i in images:\n",
        "    images1.append(change(i))\n",
        "  dk['images']=images1\n",
        "  dk['labels']=list(labels)*9\n",
        "  dk['fold']=list(fold)*9\n",
        "  path = F\"/content/gdrive/My Drive/fold_\"+str(fld) \n",
        "  np.save(path,dk)\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 1/5 [00:33<02:12, 33.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 2/5 [01:29<02:00, 40.16s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 3/5 [02:33<01:34, 47.10s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 4/5 [03:32<00:50, 50.71s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 5/5 [04:27<00:00, 53.49s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rfOv8co2nGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}