{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_7.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/internship/blob/master/attention_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LdkIU9sMbRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "667e1a3b-db7b-4ea8-fe4b-f92db6b8831c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsiPqHMGNV6-",
        "colab_type": "text"
      },
      "source": [
        "Impoting all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgxaKpOMd9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2840e292-d7c7-44d8-c937-723fc2482573"
      },
      "source": [
        "import zipfile\n",
        "import h5py\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from keras.utils import to_categorical\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from keras.applications import *\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from keras.models import Model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5OI7-tiNarO",
        "colab_type": "text"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0xeyOp7NYfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0MkL3H0Nk1z",
        "colab_type": "text"
      },
      "source": [
        "Function to shuffle data in fold and load each fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L62Y_Ub5NjNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (299,299), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=224\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  img1=np.asarray(img)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],dimension,dimension,1)),1,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z31haAgNowq",
        "colab_type": "text"
      },
      "source": [
        "Verfying model stricture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O85qsxZgNnFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(last=True):   \n",
        "  inp=Input((224,224,1,))\n",
        "\n",
        "  x=Convolution2D(64,(3,3),padding='same')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  \n",
        "  x=Convolution2D(64,(5,5),padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  \n",
        "  x=Convolution2D(64,(7,7),padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  tot=MaxPooling2D(2,2)(x)\n",
        "  tot=SpatialDropout2D(0.3,data_format='channels_last')(tot)\n",
        "\n",
        "  x=Convolution2D(128,(2,2),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  a=Activation('relu')(x)\n",
        "  x=Convolution2D(128,(3,3),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  b=Activation('relu')(x)\n",
        "  x=Convolution2D(128,(5,5),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  c=Activation('relu')(x)\n",
        "  x=Convolution2D(128,(7,7),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  d=Activation('relu')(x)\n",
        "  x=Convolution2D(128,(9,9),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  f=Activation('relu')(x)\n",
        "  tot=Concatenate()([a,b,c,d,f])\n",
        "  tot=SpatialDropout2D(0.3,data_format='channels_last')(tot)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  x=Convolution2D(64,(3,3),padding='same')(tot)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  \n",
        "  x=Convolution2D(64,(5,5),padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=MaxPooling2D(2,2)(x)\n",
        "  \n",
        "  x=Convolution2D(64,(7,7),padding='same')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  tot=MaxPooling2D(2,2)(x)\n",
        "  x=GlobalAveragePooling2D()(tot)\n",
        "  x=Dropout(0.3)(x)\n",
        "\n",
        "  x=Dense(512,activation='sigmoid')(x)\n",
        "  x=Dropout(0.5)(x)\n",
        "  x=Dense(3,activation='softmax')(x)\n",
        "  model=Model(inputs=inp,outputs=x)\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC5Qd46pTPIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48ae9810-f669-4461-f104-7b802664553f"
      },
      "source": [
        "import keras\n",
        "mod=load_model()\n",
        "mod.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 224, 224, 64) 640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 112, 112, 64) 102464      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 112, 112, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 56, 56, 64)   200768      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 28, 28, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 128)  32896       spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 128)  73856       spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  204928      spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  401536      spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 128)  663680      spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 28, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 28, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 28, 28, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 28, 28, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 28, 28, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 28, 28, 640)  0           activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_2 (SpatialDro (None, 28, 28, 640)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 64)   368704      spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 28, 28, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 64)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 14, 14, 64)   102464      max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 14, 14, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 14, 14, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 64)     200768      max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 64)     256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 64)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 64)     0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          33280       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            1539        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,391,619\n",
            "Trainable params: 2,389,571\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhQ0Y8gqO9LM",
        "colab_type": "text"
      },
      "source": [
        "Loading dictionaries to save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v924-D2yO6eR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El8PFgH5O_2L",
        "colab_type": "text"
      },
      "source": [
        "Training all layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCtGMTnKstbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(dimension,dimension,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle).reshape((224,224,1)))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    img=np.asarray(images)\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return img, labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO38-WvOPBGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db30173f-070b-499d-d3a5-c74b00e14ae1"
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=3\n",
        "  epoch=50\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model()\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(1e-3,decay=1e-3), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=2, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  del([trn_x,trn_y,trn,tst])\n",
        "  gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  for i in range(epoch):\n",
        "      hist=model.fit_generator(train_data,epochs=1,steps_per_epoch=ln//2,validation_data=([tst_x,pd.get_dummies(tst_y).values]))\n",
        "      history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 125s 100ms/step - loss: 0.8182 - accuracy: 0.6338 - val_loss: 0.5818 - val_accuracy: 0.7255\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.5635 - accuracy: 0.7444 - val_loss: 0.3950 - val_accuracy: 0.8392\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.4375 - accuracy: 0.8161 - val_loss: 0.3855 - val_accuracy: 0.8252\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 98ms/step - loss: 0.3422 - accuracy: 0.8610 - val_loss: 0.3611 - val_accuracy: 0.8497\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.2711 - accuracy: 0.8933 - val_loss: 0.2984 - val_accuracy: 0.8811\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.2259 - accuracy: 0.9135 - val_loss: 0.2528 - val_accuracy: 0.9003\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.1856 - accuracy: 0.9290 - val_loss: 0.2601 - val_accuracy: 0.8881\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.1586 - accuracy: 0.9389 - val_loss: 0.2477 - val_accuracy: 0.8969\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.1352 - accuracy: 0.9503 - val_loss: 0.2940 - val_accuracy: 0.8899\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.1222 - accuracy: 0.9552 - val_loss: 0.2112 - val_accuracy: 0.9126\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.1019 - accuracy: 0.9627 - val_loss: 0.2402 - val_accuracy: 0.9178\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0890 - accuracy: 0.9674 - val_loss: 0.3220 - val_accuracy: 0.8724\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0806 - accuracy: 0.9705 - val_loss: 0.2239 - val_accuracy: 0.9231\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0707 - accuracy: 0.9757 - val_loss: 0.2450 - val_accuracy: 0.9003\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 0.2350 - val_accuracy: 0.9126\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.2059 - val_accuracy: 0.9196\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0484 - accuracy: 0.9834 - val_loss: 0.2426 - val_accuracy: 0.9178\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 98ms/step - loss: 0.0480 - accuracy: 0.9838 - val_loss: 0.2203 - val_accuracy: 0.9196\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0412 - accuracy: 0.9858 - val_loss: 0.2508 - val_accuracy: 0.9178\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.2421 - val_accuracy: 0.9213\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.2104 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.2292 - val_accuracy: 0.9178\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 98ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.2104 - val_accuracy: 0.9231\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.2342 - val_accuracy: 0.9196\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.2445 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.2328 - val_accuracy: 0.9283\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.2647 - val_accuracy: 0.9231\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 98ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.2654 - val_accuracy: 0.9318\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.2581 - val_accuracy: 0.9231\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.2524 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.2381 - val_accuracy: 0.9213\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.2416 - val_accuracy: 0.9283\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.2426 - val_accuracy: 0.9213\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 121s 97ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.2684 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.2578 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.2560 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.2634 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.2591 - val_accuracy: 0.9283\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.2329 - val_accuracy: 0.9231\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.2606 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.2739 - val_accuracy: 0.9248\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.2737 - val_accuracy: 0.9371\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.2576 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.2647 - val_accuracy: 0.9283\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.2427 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.2909 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.2706 - val_accuracy: 0.9301\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.2674 - val_accuracy: 0.9336\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.2876 - val_accuracy: 0.9266\n",
            "Epoch 1/1\n",
            "1246/1246 [==============================] - 122s 98ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.2899 - val_accuracy: 0.9266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDsmA9xTYWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e7fdf3f0-306d-4527-a3d7-53da04c70455"
      },
      "source": [
        "plt.plot(history_last[fold]['loss'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff5809215c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWsq7E05tY_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index=str(index)\n",
        "type='augment'\n",
        "model='attention'\n",
        "path = F\"/content/gdrive/My Drive/\"+model \n",
        "np.save(path+'/best_accuracy_all_fold1_wn.npy',best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold1_wn.npy',final_accuracy_last)\n",
        "np.save(path+'/history_all_fold1_wn.npy',history_last)\n",
        "np.save(path+'/answers_all_fold1_wn.npy',answers_last)\n",
        "np.save(path+'/predictions_all_fold1_wn.npy',predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold1_wn.npy',predictions_last_best)\n",
        "np.save(path+'/times_all_fold1_wn.npy',times_last)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iggbD32hv__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab6e66cf-7e8b-4a03-fe62-3be597e9740a"
      },
      "source": [
        "new_acc"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9265734265734266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGV0t8YbjIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}