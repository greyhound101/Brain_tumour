{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet_1_145_bs_18.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e531ce8d22a945079695a74a986aa237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4878be281f2149dd8fe1b83eaa19034f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d247905d1ef4e2eb53da02236648733",
              "IPY_MODEL_01faf0275efd47c1b1ec4db8558d9f20"
            ]
          }
        },
        "4878be281f2149dd8fe1b83eaa19034f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d247905d1ef4e2eb53da02236648733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11f867b05c0f4f37bf480397ab9535bc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fef0da05531545a5b8fec5eed41336d2"
          }
        },
        "01faf0275efd47c1b1ec4db8558d9f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16bf974ef36b4b959fe54ba1a670bc92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:02&lt;00:00, 94.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65f69d9861d640c4a1b8663195ea7628"
          }
        },
        "11f867b05c0f4f37bf480397ab9535bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fef0da05531545a5b8fec5eed41336d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16bf974ef36b4b959fe54ba1a670bc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65f69d9861d640c4a1b8663195ea7628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/Brain_tumour/blob/master/alexnet_1_145_bs_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "outputId": "5d742f1a-b313-4d06-9957-8f4183b30d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVtsa9p7GmxJ",
        "outputId": "9218c7c7-41ce-4c52-b477-05aaa67c56a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install pytorch2keras "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch2keras\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/ef/94848369da7ef7ca38916e4a743c08cff7b8dc98832a1931bd78f60c6104/pytorch2keras-0.2.4.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from pytorch2keras) (2.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from pytorch2keras) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch2keras) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch2keras) (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pytorch2keras) (0.7.0+cu101)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/ee/bc7bc88fc8449266add978627e90c363069211584b937fd867b0ccc59f09/onnx-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 6.7MB/s \n",
            "\u001b[?25hCollecting onnx2keras\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/68/647c88eb96546ebef79bf66ea633efca3e8cda866951a5e1003229880b36/onnx2keras-0.0.23.tar.gz\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->pytorch2keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->pytorch2keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->pytorch2keras) (3.13)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (0.35.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (0.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->pytorch2keras) (0.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch2keras) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pytorch2keras) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->pytorch2keras) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (4.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->pytorch2keras) (0.4.8)\n",
            "Building wheels for collected packages: pytorch2keras, onnx2keras\n",
            "  Building wheel for pytorch2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch2keras: filename=pytorch2keras-0.2.4-cp36-none-any.whl size=29665 sha256=aa84c33de67ffbbc4a8fe51ee71992e7f68b99045d8b5b2f6fd45285527d9bdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/8b/2e/e2b6ae7a78ad4661e6156700bf96816309013f89f7a21f82d7\n",
            "  Building wheel for onnx2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx2keras: filename=onnx2keras-0.0.23-cp36-none-any.whl size=24159 sha256=8d5607e1949dd7156ad0f8b869e64e81b3123d0e0c8f5d6455f8310cc60e9c98\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/d1/5a/644cd9e957d01977c2e7c5bcb75d8172ba0eab831e2471128d\n",
            "Successfully built pytorch2keras onnx2keras\n",
            "Installing collected packages: onnx, onnx2keras, pytorch2keras\n",
            "Successfully installed onnx-1.7.0 onnx2keras-0.0.23 pytorch2keras-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg"
      },
      "source": [
        "import zipfile\n",
        "import h5py\n",
        "import tensorflow\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras\n",
        "import pandas as pd\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import zipfile\n",
        "import h5py\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import glob, os\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import gc\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moU67eo5HOQl"
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/check.npy\" \n",
        "df=np.load(path,allow_pickle=True)\n",
        "df=df.item()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F"
      },
      "source": [
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels.loc[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=pd.DataFrame()\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    labels=pd.concat([labels,lbl],0)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images), labels.values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG"
      },
      "source": [
        "\n",
        "#shuffle samples\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "\n",
        "\n",
        "#change targets\n",
        "def change(img):\n",
        "    resized = cv2.resize(img, (299,299), interpolation = cv2.INTER_AREA )\n",
        "    return resized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get train and test splits\n",
        "def get_trn_tst(df,tst_fold):\n",
        "  dimension=224\n",
        "  idx=np.asarray(df['fold'])\n",
        "  y=np.asarray(df['label'])\n",
        "  y-=1\n",
        "  img=np.asarray(df['image'])\n",
        "  img1=[]\n",
        "  img1=np.asarray(img)\n",
        "  del([img])\n",
        "  gc.collect()\n",
        "  trn_y=np.asarray(y[(idx!=tst_fold)])\n",
        "  trn_img=np.asarray(img1[(idx!=tst_fold)])\n",
        "  tst_y=np.asarray(y[(idx==tst_fold)])\n",
        "  tst_img=img1[idx==tst_fold]\n",
        "  trn_img=np.repeat(trn_img.reshape((trn_img.shape[0],dimension,dimension,1)),3,axis=3)\n",
        "  tst_img=np.repeat(tst_img.reshape((tst_img.shape[0],dimension,dimension,1)),3,axis=3)\n",
        "  return (trn_img.copy(),trn_y.copy()),(tst_img.copy(),tst_y.copy())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "outputId": "608abb23-36f1-4f94-cd89-173f84411f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e531ce8d22a945079695a74a986aa237",
            "4878be281f2149dd8fe1b83eaa19034f",
            "1d247905d1ef4e2eb53da02236648733",
            "01faf0275efd47c1b1ec4db8558d9f20",
            "11f867b05c0f4f37bf480397ab9535bc",
            "fef0da05531545a5b8fec5eed41336d2",
            "16bf974ef36b4b959fe54ba1a670bc92",
            "65f69d9861d640c4a1b8663195ea7628"
          ]
        }
      },
      "source": [
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "mod=models.alexnet(pretrained=True)\n",
        "input_np = np.random.uniform(0, 1, (1, 3, 224,224))\n",
        "input_var = torch.FloatTensor(input_np)\n",
        "\n",
        "from pytorch2keras import pytorch_to_keras\n",
        "# we should specify shape of the input tensor\n",
        "k_model = pytorch_to_keras(mod, input_var, [(3, 224,224,)], verbose=True,name_policy='keep',change_ordering='HWC')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e531ce8d22a945079695a74a986aa237",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch2keras:Converter is called.\n",
            "WARNING:pytorch2keras:Name policy isn't supported now.\n",
            "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
            "DEBUG:pytorch2keras:Input_names:\n",
            "DEBUG:pytorch2keras:['input_0']\n",
            "DEBUG:pytorch2keras:Output_names:\n",
            "DEBUG:pytorch2keras:['output_0']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "graph(%input_0 : Float(1:150528, 3:50176, 224:224, 224:1),\n",
            "      %features.0.weight : Float(64:363, 3:121, 11:11, 11:1),\n",
            "      %features.0.bias : Float(64:1),\n",
            "      %features.3.weight : Float(192:1600, 64:25, 5:5, 5:1),\n",
            "      %features.3.bias : Float(192:1),\n",
            "      %features.6.weight : Float(384:1728, 192:9, 3:3, 3:1),\n",
            "      %features.6.bias : Float(384:1),\n",
            "      %features.8.weight : Float(256:3456, 384:9, 3:3, 3:1),\n",
            "      %features.8.bias : Float(256:1),\n",
            "      %features.10.weight : Float(256:2304, 256:9, 3:3, 3:1),\n",
            "      %features.10.bias : Float(256:1),\n",
            "      %classifier.1.weight : Float(4096:9216, 9216:1),\n",
            "      %classifier.1.bias : Float(4096:1),\n",
            "      %classifier.4.weight : Float(4096:4096, 4096:1),\n",
            "      %classifier.4.bias : Float(4096:1),\n",
            "      %classifier.6.weight : Float(1000:4096, 4096:1),\n",
            "      %classifier.6.bias : Float(1000:1)):\n",
            "  %17 : Float(1:193600, 64:3025, 55:55, 55:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%input_0, %features.0.weight, %features.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0\n",
            "  %18 : Float(1:193600, 64:3025, 55:55, 55:1) = onnx::Relu(%17) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %19 : Float(1:46656, 64:729, 27:27, 27:1) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:576:0\n",
            "  %20 : Float(1:139968, 192:729, 27:27, 27:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %features.3.weight, %features.3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0\n",
            "  %21 : Float(1:139968, 192:729, 27:27, 27:1) = onnx::Relu(%20) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %22 : Float(1:32448, 192:169, 13:13, 13:1) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:576:0\n",
            "  %23 : Float(1:64896, 384:169, 13:13, 13:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %features.6.weight, %features.6.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0\n",
            "  %24 : Float(1:64896, 384:169, 13:13, 13:1) = onnx::Relu(%23) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %25 : Float(1:43264, 256:169, 13:13, 13:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %features.8.weight, %features.8.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0\n",
            "  %26 : Float(1:43264, 256:169, 13:13, 13:1) = onnx::Relu(%25) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %27 : Float(1:43264, 256:169, 13:13, 13:1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %features.10.weight, %features.10.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:416:0\n",
            "  %28 : Float(1:43264, 256:169, 13:13, 13:1) = onnx::Relu(%27) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %29 : Float(1:9216, 256:36, 6:6, 6:1) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:576:0\n",
            "  %30 : Float(1:9216, 256:36, 6:6, 6:1) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%29) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:926:0\n",
            "  %31 : Float(1:9216, 9216:1) = onnx::Flatten[axis=1](%30) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:973:0\n",
            "  %32 : Float(1:4096, 4096:1) = onnx::Gemm[alpha=1., beta=1., transB=1](%31, %classifier.1.weight, %classifier.1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1674:0\n",
            "  %33 : Float(1:4096, 4096:1) = onnx::Relu(%32) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:973:0\n",
            "  %34 : Float(1:4096, 4096:1) = onnx::Gemm[alpha=1., beta=1., transB=1](%33, %classifier.4.weight, %classifier.4.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1674:0\n",
            "  %35 : Float(1:4096, 4096:1) = onnx::Relu(%34) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1117:0\n",
            "  %output_0 : Float(1:1000, 1000:1) = onnx::Gemm[alpha=1., beta=1., transB=1](%35, %classifier.6.weight, %classifier.6.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1674:0\n",
            "  return (%output_0)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:[(3, 224, 224)]\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> input_0.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> output_0.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight classifier.1.bias with shape (4096,).\n",
            "DEBUG:onnx2keras:Found weight classifier.1.weight with shape (4096, 9216).\n",
            "DEBUG:onnx2keras:Found weight classifier.4.bias with shape (4096,).\n",
            "DEBUG:onnx2keras:Found weight classifier.4.weight with shape (4096, 4096).\n",
            "DEBUG:onnx2keras:Found weight classifier.6.bias with shape (1000,).\n",
            "DEBUG:onnx2keras:Found weight classifier.6.weight with shape (1000, 4096).\n",
            "DEBUG:onnx2keras:Found weight features.0.bias with shape (64,).\n",
            "DEBUG:onnx2keras:Found weight features.0.weight with shape (64, 3, 11, 11).\n",
            "DEBUG:onnx2keras:Found weight features.10.bias with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight features.10.weight with shape (256, 256, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight features.3.bias with shape (192,).\n",
            "DEBUG:onnx2keras:Found weight features.3.weight with shape (192, 64, 5, 5).\n",
            "DEBUG:onnx2keras:Found weight features.6.bias with shape (384,).\n",
            "DEBUG:onnx2keras:Found weight features.6.weight with shape (384, 192, 3, 3).\n",
            "DEBUG:onnx2keras:Found weight features.8.bias with shape (256,).\n",
            "DEBUG:onnx2keras:Found weight features.8.weight with shape (256, 384, 3, 3).\n",
            "DEBUG:onnx2keras:Found input input_0 with shape (3, 224, 224)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 17\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [11, 11], 'pads': [2, 2, 2, 2], 'strides': [4, 4], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
            "DEBUG:onnx2keras:Check input 1 (name features.0.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name features.0.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17/BiasAdd:0\", shape=(None, 64, 55, 55), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 18\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 17).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18/Relu:0\", shape=(None, 64, 55, 55), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 19\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [3, 3], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 18).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19/MaxPool:0\", shape=(None, 64, 27, 27), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 20\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [5, 5], 'pads': [2, 2, 2, 2], 'strides': [1, 1], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 19).\n",
            "DEBUG:onnx2keras:Check input 1 (name features.3.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name features.3.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"20/BiasAdd:0\", shape=(None, 192, 27, 27), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 21\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 20).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"21/Relu:0\", shape=(None, 192, 27, 27), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 22\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [3, 3], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 21).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"22/MaxPool:0\", shape=(None, 192, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 23\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 22).\n",
            "DEBUG:onnx2keras:Check input 1 (name features.6.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name features.6.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"23/BiasAdd:0\", shape=(None, 384, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 24\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 23).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"24/Relu:0\", shape=(None, 384, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 25\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 24).\n",
            "DEBUG:onnx2keras:Check input 1 (name features.8.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name features.8.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"25/BiasAdd:0\", shape=(None, 256, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 26\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 25).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"26/Relu:0\", shape=(None, 256, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Conv\n",
            "DEBUG:onnx2keras:node_name: 27\n",
            "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [3, 3], 'pads': [1, 1, 1, 1], 'strides': [1, 1], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 26).\n",
            "DEBUG:onnx2keras:Check input 1 (name features.10.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name features.10.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:conv:Conv with bias\n",
            "DEBUG:onnx2keras:conv:2D convolution\n",
            "DEBUG:onnx2keras:conv:Paddings exist, add ZeroPadding layer\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"27/BiasAdd:0\", shape=(None, 256, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Relu\n",
            "DEBUG:onnx2keras:node_name: 28\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 27).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"28/Relu:0\", shape=(None, 256, 13, 13), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MaxPool\n",
            "DEBUG:onnx2keras:node_name: 29\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [3, 3], 'pads': [0, 0, 0, 0], 'strides': [2, 2], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 28).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"29/MaxPool:0\", shape=(None, 256, 6, 6), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: AveragePool\n",
            "DEBUG:onnx2keras:node_name: 30\n",
            "DEBUG:onnx2keras:node_params: {'kernel_shape': [1, 1], 'strides': [1, 1], 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 29).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:avgpool:Use `same` padding parameters.\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"30/AvgPool:0\", shape=(None, 256, 6, 6), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Flatten\n",
            "DEBUG:onnx2keras:node_name: 31\n",
            "DEBUG:onnx2keras:node_params: {'axis': 1, 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 30).\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:flatten:Convert inputs to Keras/TF layers if needed.\n",
            "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"31/Reshape:0\", shape=(None, 9216), dtype=float32)\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: Gemm\n",
            "DEBUG:onnx2keras:node_name: 32\n",
            "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': 'HWC', 'name_policy': 'keep'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name 31).\n",
            "DEBUG:onnx2keras:Check input 1 (name classifier.1.weight).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:Check input 2 (name classifier.1.bias).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
            "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
            "DEBUG:onnx2keras:... found all, continue\n",
            "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
            "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
            "DEBUG:onnx2keras:gemm:Input units 9216, output units 4096.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq"
      },
      "source": [
        "k_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y"
      },
      "source": [
        "def load_model(last=True):\n",
        "  mod=models.alexnet(pretrained=True)\n",
        "  input_np = np.random.uniform(0, 1, (1, 3, 224,224))\n",
        "  input_var = torch.FloatTensor(input_np)\n",
        "  model = pytorch_to_keras(mod, input_var, [(3, 224,224,)], verbose=True,name_policy='keep',change_ordering='HWC')  \n",
        "  out_1=model.layers[-2].output\n",
        "  out=Dense(3,activation='softmax')(out_1)\n",
        "  model=Model(inputs=model.input,outputs=out)\n",
        "  if last:\n",
        "    for i in range(len(model.layers)):\n",
        "        model.layers[i].trainable = False\n",
        "  model.layers[-1].trainable=True\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u"
      },
      "source": [
        "best_accuracy_last={}\n",
        "final_accuracy_last={}\n",
        "history_last={}\n",
        "answers_last={}\n",
        "predictions_last={}\n",
        "predictions_last_best={}\n",
        "times_last={}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC"
      },
      "source": [
        "  def upd(dk,data):\n",
        "    if dk==0:\n",
        "        dk=data\n",
        "    else:\n",
        "        for ky in data.keys():\n",
        "            dk[ky].extend(data[ky])\n",
        "    return dk\n",
        "  index=1\n",
        "  epoch=50\n",
        "  pre_acc=0\n",
        "  best=0\n",
        "  fold='fold_'+str(index)\n",
        "  trn,tst=get_trn_tst(df,index)\n",
        "  history_last[fold]=0\n",
        "\n",
        "\n",
        "\n",
        "  plt.imshow(trn[0][0])\n",
        "  plt.show()\n",
        "  plt.imshow(tst[0][0])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  trn_x,trn_y=unison_shuffled_copies(trn[0],trn[1])\n",
        "  tst_x,tst_y=unison_shuffled_copies(tst[0],tst[1])\n",
        "\n",
        "\n",
        "\n",
        "  model=load_model(last=False)\n",
        "\n",
        "\n",
        "  \n",
        "  #compiling the model\n",
        "  model.compile(optimizer=Adam(3e-4,decay=1e-3), \n",
        "                     loss='categorical_crossentropy', \n",
        "                     metrics=['accuracy'])\n",
        "  train_data = DataGenerator(trn_x,pd.get_dummies(trn_y), batch_size=2, augment=True)\n",
        "  ln=len(trn_y)\n",
        "  del([trn_x,trn_y,trn,tst])\n",
        "  gc.collect()\n",
        "  #fitting the model\n",
        "  #timing\n",
        "  start=time.time()\n",
        "  for i in range(epoch):\n",
        "      hist=model.fit_generator(train_data,epochs=1,steps_per_epoch=ln//4)\n",
        "      history_last[fold]=upd(history_last[fold],hist.history)\n",
        "\n",
        "  end=time.time()\n",
        "  times_last[fold]=end-start\n",
        "\n",
        "  #getting the prediction \n",
        "  pre=model.predict(tst_x)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #select the maximum position\n",
        "  pre=np.argmax(pre,1)\n",
        "  predictions_last[fold]=pre\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  #getting the accuracy\n",
        "  new_acc=accuracy_score(pre,tst_y)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #storing the predictions\n",
        "  final_accuracy_last[fold]=new_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #storing the answers\n",
        "  answers_last[fold]=tst_y\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  #freeing memory\n",
        "  del([tst_x,tst_y])\n",
        "  gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVk9YO8elt-M"
      },
      "source": [
        "index=str(index)\n",
        "type='decay_145_bs_18'\n",
        "model='alexnet'\n",
        "path = F\"/content/gdrive/My Drive/\"+model \n",
        "np.save(path+\"/best_accuracy_all_fold_\"+index+\"_\"+model+\"_\"+type+\".npy\",best_accuracy_last)\n",
        "np.save(path+'/final_accuracy_all_fold'+index+\"_\"+model+\"_\"+type+\".npy\",final_accuracy_last)\n",
        "np.save(path+'/history_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",history_last)\n",
        "np.save(path+'/answers_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",answers_last)\n",
        "np.save(path+'/predictions_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last)\n",
        "np.save(path+'/predictions_all_best_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",predictions_last_best)\n",
        "np.save(path+'/times_all_fold_'+index+\"_\"+model+\"_\"+type+\".npy\",times_last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykeXpxh_lu8L"
      },
      "source": [
        "plt.plot(history_last[fold]['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm4CwPSqp7ru"
      },
      "source": [
        "new_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOdQm2sOWzCv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}