{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lr_tune_3e-5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg23a3g2hg4Z1JHdGLR6zv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/Brain_tumour/blob/master/lr_tune_3e_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyAd8cKiv5Ej",
        "outputId": "0f57ed71-72c9-4cc1-ba71-2de2b112bc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80WH-bjfv5vK"
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/gdrive/My Drive/archive.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaWA_gNvxBJr",
        "outputId": "da6d750d-f95f-4b18-c166-6953399e8a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re-bThzGw-vj"
      },
      "source": [
        "import copy\n",
        "from datetime import timedelta, datetime\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pydicom\n",
        "import pytest\n",
        "import scipy.ndimage as ndimage\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "from skimage import measure, morphology, segmentation\n",
        "from time import time, sleep\n",
        "from tqdm import trange, tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, random_split, DistributedSampler, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "import warnings"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MepiJCewTlF"
      },
      "source": [
        "class CTTensorsDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.tensor_files = [Path(i) for i in glob.glob('/content/ID*')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensor_files)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if torch.is_tensor(item):\n",
        "            item = item.tolist()\n",
        "\n",
        "        image = torch.load(self.tensor_files[item])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return {\n",
        "            'patient_id': self.tensor_files[item].stem,\n",
        "            'image': image\n",
        "        }\n",
        "\n",
        "    def mean(self):\n",
        "        cum = 0\n",
        "        for i in range(len(self)):\n",
        "            sample = self[i]['image']\n",
        "            cum += torch.mean(sample).item()\n",
        "\n",
        "        return cum / len(self)\n",
        "\n",
        "    def random_split(self, val_size: float):\n",
        "        num_val = int(val_size * len(self))\n",
        "        num_train = len(self) - num_val\n",
        "        return random_split(self, [num_train, num_val])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPhMVZeywtjZ"
      },
      "source": [
        "class ZeroCenter:\n",
        "    def __init__(self, pre_calculated_mean):\n",
        "        self.pre_calculated_mean = pre_calculated_mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor - self.pre_calculated_mean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCZEkwnKwyg9"
      },
      "source": [
        "root_dir = '/kaggle/input/osic-cached-dataset'\n",
        "test_dir = '/kaggle/input/osic-pulmonary-fibrosis-progression/test'\n",
        "model_file = '/kaggle/working/diophantus.pt'\n",
        "resize_dims = (40, 256, 256)\n",
        "clip_bounds = (-1000, 200)\n",
        "watershed_iterations = 1\n",
        "pre_calculated_mean = 0.02865046213070556\n",
        "latent_features = 10\n",
        "batch_size = 16\n",
        "learning_rate = 3e-5\n",
        "num_epochs = 10\n",
        "val_size = 0.2\n",
        "tensorboard_dir = '/kaggle/working/runs'\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1lVm3VSweak"
      },
      "source": [
        "import glob\n",
        "train = CTTensorsDataset(\n",
        "    transform=ZeroCenter(pre_calculated_mean=pre_calculated_mean)\n",
        ")\n",
        "cum = 0\n",
        "for i in range(len(train)):\n",
        "    sample = train[i]['image']\n",
        "    cum += torch.mean(sample).item()\n",
        "\n",
        "assert cum / len(train) == pytest.approx(0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTW4lnVLw2J1"
      },
      "source": [
        "class VarAutoEncoder(nn.Module):\n",
        "    def __init__(self, latent_features=latent_features):\n",
        "        super(VarAutoEncoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv3d(1, 16, 3)\n",
        "        self.conv2 = nn.Conv3d(16, 32, 3)\n",
        "        self.conv3 = nn.Conv3d(32, 96, 2)\n",
        "        self.conv4 = nn.Conv3d(96, 1, 1)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=3, stride=3, return_indices=True)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.fc1 = nn.Linear(10 * 10, latent_features)\n",
        "        self.fc2 = nn.Linear(10 * 10, latent_features)\n",
        "        self.act=nn.LeakyReLU(0.1)\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_features, 10 * 10)\n",
        "        self.deconv0 = nn.ConvTranspose3d(1, 96, 1)\n",
        "        self.deconv1 = nn.ConvTranspose3d(96, 32, 2)\n",
        "        self.deconv2 = nn.ConvTranspose3d(32, 16, 3)\n",
        "        self.deconv3 = nn.ConvTranspose3d(16, 1, 3)\n",
        "        self.unpool0 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "        self.unpool1 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "        self.unpool2 = nn.MaxUnpool3d(kernel_size=3, stride=3)\n",
        "        self.unpool3 = nn.MaxUnpool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def encode(self, x, return_partials=True):\n",
        "        # Encoder\n",
        "        x = self.act(self.conv1(x))\n",
        "        up3out_shape = x.shape\n",
        "        x, i1 = self.pool1(x)\n",
        "\n",
        "        x = self.act(self.conv2(x))\n",
        "        up2out_shape = x.shape\n",
        "        x, i2 = self.pool2(x)\n",
        "\n",
        "        x = self.act(self.conv3(x))\n",
        "        up1out_shape = x.shape\n",
        "        x, i3 = self.pool3(x)\n",
        "\n",
        "        x = self.act(self.conv4(x))\n",
        "        up0out_shape = x.shape\n",
        "        x, i4 = self.pool4(x)\n",
        "\n",
        "        x = x.view(-1, 10 * 10)\n",
        "        \n",
        "        mu = self.act(self.fc1(x))\n",
        "        log_var = self.act(self.fc2(x))\n",
        "        \n",
        "        if return_partials:\n",
        "            \n",
        "            return mu, log_var, up3out_shape, i1, up2out_shape, i2, up1out_shape, i3, \\\n",
        "                   up0out_shape, i4\n",
        "\n",
        "        else:\n",
        "            return mu, log_var\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var, up3out_shape, i1, up2out_shape, i2, \\\n",
        "        up1out_shape, i3, up0out_shape, i4 = self.encode(x)\n",
        "        \n",
        "        z = self.reparameterize(mu, log_var)\n",
        "       \n",
        "        # Decoder\n",
        "        x = F.relu(self.fc3(z))\n",
        "        x = x.view(-1, 1, 1, 10, 10)\n",
        "        x = self.unpool0(x, output_size=up0out_shape, indices=i4)\n",
        "        x = self.act(self.deconv0(x))\n",
        "        x = self.unpool1(x, output_size=up1out_shape, indices=i3)\n",
        "        x = self.act(self.deconv1(x))\n",
        "        x = self.unpool2(x, output_size=up2out_shape, indices=i2)\n",
        "        x = self.act(self.deconv2(x))\n",
        "        x = self.unpool3(x, output_size=up3out_shape, indices=i1)\n",
        "        x = self.act((self.deconv3(x)))\n",
        "\n",
        "        return x, mu, log_var"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uggc0K_w4Z0"
      },
      "source": [
        "t0 = time()\n",
        "\n",
        "# Load the data\n",
        "data = CTTensorsDataset(\n",
        "    transform=ZeroCenter(pre_calculated_mean=pre_calculated_mean)\n",
        ")\n",
        "train_set, val_set = data.random_split(val_size)\n",
        "datasets = {'train': train_set, 'val': val_set}\n",
        "dataloaders = {\n",
        "    x: DataLoader(\n",
        "        datasets[x],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(x == 'train'),\n",
        "        num_workers=2\n",
        "    ) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "# Prepare for training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VarAutoEncoder(latent_features=latent_features).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "best_model_wts = None\n",
        "best_loss = np.inf\n",
        "\n",
        "date_time = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "log_dir = Path(tensorboard_dir) / f'{date_time}'\n",
        "writer = SummaryWriter(log_dir)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNn3kzUZw4cU",
        "outputId": "974af66d-ef20-4a20-99fc-9443a104733d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "total_loss=  {'train':[],'val':[]}\n",
        "for epoch in range(50):\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()  # Set model to training mode\n",
        "        else:\n",
        "            model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_preds = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        bar = tqdm(dataloaders[phase])\n",
        "        for inputs in bar:\n",
        "            bar.set_description(f'Epoch {epoch + 1} {phase}'.ljust(20))\n",
        "            inputs = inputs['image'].to(device, dtype=torch.float)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs, mu, log_var = model(inputs)\n",
        "                \n",
        "                # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
        "                reconst_loss = F.mse_loss(outputs, inputs, size_average=False)\n",
        "                kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "                \n",
        "                loss =  reconst_loss + kl_div\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_preds += inputs.size(0)\n",
        "            bar.set_postfix(loss=f'{running_loss / running_preds:0.6f}')\n",
        "        total_loss[phase].append(loss.item()  )\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
        "\n",
        "        # deep copy the model\n",
        "        if phase == 'val' and epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_wts, model_file)\n",
        "\n",
        "# load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "print(f'Done! Time {timedelta(seconds=time() - t0)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train       :   0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Epoch 1 train       : 100%|██████████| 9/9 [00:28<00:00,  3.16s/it, loss=572766.735372]\n",
            "Epoch 1 val         : 100%|██████████| 3/3 [00:03<00:00,  1.11s/it, loss=554108.356696]\n",
            "Epoch 2 train       : 100%|██████████| 9/9 [00:27<00:00,  3.04s/it, loss=572064.950798]\n",
            "Epoch 2 val         : 100%|██████████| 3/3 [00:03<00:00,  1.08s/it, loss=554057.538170]\n",
            "Epoch 3 train       : 100%|██████████| 9/9 [00:27<00:00,  3.01s/it, loss=571508.537234]\n",
            "Epoch 3 val         : 100%|██████████| 3/3 [00:03<00:00,  1.12s/it, loss=554006.344866]\n",
            "Epoch 4 train       :  22%|██▏       | 2/9 [00:07<00:26,  3.77s/it, loss=541462.796875]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkYBl9H52A9p"
      },
      "source": [
        "sns.lineplot(y=total_loss['train'],x=list(range(len(total_loss['train']))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtoWy6n5L9i"
      },
      "source": [
        "sns.lineplot(y=total_loss['val'],x=list(range(len(total_loss['val']))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAyXLc5s7zlM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}